### ðŸ§© Quellenbezug des Systemprompts

**ROLE & SCOPE**  
*Quelle:* Zhao et al., 2025 â€“ *Deriving Insights from Enhanced Accuracy: Leveraging Prompt Engineering in Custom GPT for Assessing Chinese Nursing Licensing Exam*  
> Beschreibt die Entwicklung eines **Custom GPT** mit **Prompt Engineering**, **Retrieval-Augmented Generation (RAG)** und **semantic search**.  
> â†’ Belegt, dass spezialisierte GPTs mit klar definiertem Zweck + RAG-Integration deutlich hÃ¶here Genauigkeit erreichen.  
> â†’ Deshalb ist **TUna** strikt auf TU-Studienorganisation beschrÃ¤nkt.

---

**BEHAVIORAL IDENTITY**  
*Quelle:* Salewski et al., 2024 â€“ *In-Context Impersonation Reveals Large Language Modelsâ€™ Strengths and Biases*  
> Zeigt, dass Rollen-Prompts Verhalten, Stil und Bias signifikant beeinflussen.  
> â†’ â€žAlways speak as institutional assistantâ€œ stellt RollenstabilitÃ¤t und NeutralitÃ¤t sicher.

---

**CORE REASONING LOOP**  
*Quellen:* Li et al., 2024 â€“ *Confidence Matters (Revisiting Intrinsic Self-Correction Capabilities of LLMs)* Â· Sun et al., 2024 â€“ *Prompt Chaining vs Stepwise Prompt*  
> Li et al. fÃ¼hren das **If-or-Else (IoE)**-Prinzip ein, bei dem LLMs ihre eigene Sicherheit einschÃ¤tzen und nur bei Unsicherheit revidieren â†’ umgesetzt in Schritt 5.  
> Sun et al. zeigen, dass mehrstufiges Draftâ€“Critiqueâ€“Refine-Prompting bessere Resultate liefert â†’ umgesetzt in Schritt 6.

---

**RESPONSE STRUCTURE**  
*Quelle:* Sun et al., 2024 â€“ *Prompt Chaining / Refinement in Text Summarization*  
> Klare Phasenstruktur (Draft â†’ Critique â†’ Refine) und explizite Abschnitte (Short Answer, Steps, Details â€¦) erhÃ¶hen Transparenz und Lesbarkeit.

---

**HALLUCINATION GUARD**  
*Quellen:* Tran Nhat et al., 2025 â€“ *Kickoff Day 1: Prompt Engineering Basics & Chain-of-Verification* Â· Zhao et al., 2025  
> *Kickoff Day 1* betont QuellenprÃ¼fung, Fehleranalyse und Chain-of-Verification zur Reduktion von Halluzinationen.  
> *Zhao et al.* zeigen, dass Custom GPTs mit RAG-gestÃ¼tzter Wissensbasis weniger falsche Antworten produzieren.  
> â†’ Regel: *â€žNever invent / state uncertainty.â€œ*

---

**CRISIS MODE**  
*Quelle:* Tran Nhat et al., 2025 â€“ *Kickoff Day 2: Ethical Prompting & Empathy in LLMs*  
> Beschreibt den Umgang mit emotional aufgeladenen oder krisenbezogenen Eingaben.  
> â†’ Empathische, aber abgegrenzte Reaktionen entsprechen HCI-Ethikprinzipien (Empathie ohne Rollensprung).

---

**SECURITY & ETHICS**  
*Quelle:* Tran Nhat et al., 2025 â€“ *Kickoff Day 2: Bias, Accountability & Transparency in AI Systems*  
> Betonung von Verantwortlichkeit und Transparenz im Prompt-Design.  
> â†’ Regeln gegen Prompt-Injection und fÃ¼r DSGVO-KonformitÃ¤t folgen direkt den Lehrinhalten aus *Kickoff Day 2*.

---

**OUTPUT LANGUAGE**  
*Quelle:* Zhao et al., 2025 â€“ *Deriving Insights from Enhanced Accuracy â€¦ (Custom GPT for Nursing Exam)*  
> Das Paper stellt den Einsatz von **semantic search und intent-basiertem Retrieval** zur Kontextanpassung vor.  
> â†’ Die automatische Sprachspiegelung in TUna folgt diesem Prinzip der kontextsensitiven Antwortgenerierung.
